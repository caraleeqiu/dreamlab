import { uploadToR2 } from './r2'
import { createLogger } from './logger'

const logger = createLogger('imagen')

const GEMINI_API_BASE = 'https://generativelanguage.googleapis.com/v1beta/models'
// gemini-2.0-flash-exp supports responseModalities: ["IMAGE"]
const IMAGEN_MODEL = 'gemini-2.0-flash-exp'

/**
 * Generate a storyboard frame image via Gemini 2.0 Flash image generation.
 *
 * Used before submitting clips to Kling/Seedance so every clip starts from
 * a consistent, art-directed first frame (all generated by the same model
 * with the same style anchor).
 *
 * Returns the R2 public URL of the generated image, or null on failure.
 * Failures are non-fatal — callers fall back to the influencer frontal image.
 */
export async function generateStoryboardFrame(params: {
  shotDescription: string
  styleAnchor: string        // character appearance + scene + lighting lock
  aspectRatio?: string       // '9:16' | '16:9' | '1:1'
  jobId: number
  clipIndex: number
}): Promise<string | null> {
  const { shotDescription, styleAnchor, aspectRatio = '9:16', jobId, clipIndex } = params

  const prompt = [
    `Storyboard frame for a short-form social video.`,
    `Style anchor: ${styleAnchor}`,
    `Shot: ${shotDescription}`,
    `Format: ${aspectRatio} vertical frame, cinematic composition, clean edges.`,
    `Output: single frame, no text overlays, no watermarks.`,
  ].join(' ')

  const apiKey = process.env.GEMINI_API_KEY
  if (!apiKey) {
    logger.warn('GEMINI_API_KEY not set — skipping storyboard generation')
    return null
  }

  try {
    const res = await fetch(
      `${GEMINI_API_BASE}/${IMAGEN_MODEL}:generateContent?key=${apiKey}`,
      {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          contents: [{ parts: [{ text: prompt }] }],
          generationConfig: { responseModalities: ['IMAGE', 'TEXT'] },
        }),
        signal: AbortSignal.timeout(30_000),
      },
    )

    if (!res.ok) {
      const err = await res.text()
      logger.warn('Imagen HTTP error', { status: res.status, err: err.slice(0, 200) })
      return null
    }

    const data = await res.json()
    // Response: candidates[0].content.parts[].inlineData.{mimeType, data}
    const parts = data?.candidates?.[0]?.content?.parts ?? []
    const imgPart = parts.find((p: { inlineData?: { mimeType?: string; data?: string } }) =>
      p.inlineData?.mimeType?.startsWith('image/')
    )

    if (!imgPart?.inlineData?.data) {
      logger.warn('Imagen returned no image part', { jobId, clipIndex })
      return null
    }

    const buffer = Buffer.from(imgPart.inlineData.data, 'base64')
    const ext = imgPart.inlineData.mimeType === 'image/png' ? 'png' : 'jpg'
    const key = `jobs/${jobId}/storyboard/clip_${clipIndex}.${ext}`
    const url = await uploadToR2(key, buffer, imgPart.inlineData.mimeType)

    logger.info('storyboard frame generated', { jobId, clipIndex, url })
    return url

  } catch (err) {
    logger.warn('Imagen generation failed (non-fatal)', { jobId, clipIndex, err: String(err) })
    return null
  }
}

/**
 * Generate storyboard frames for all clips in parallel.
 * Returns an array of URLs (null where generation failed — use frontal image as fallback).
 */
export async function generateStoryboardFrames(params: {
  clips: Array<{ index: number; shot_description: string; consistency_anchor?: string }>
  styleAnchor: string
  aspectRatio?: string
  jobId: number
}): Promise<(string | null)[]> {
  return Promise.all(
    params.clips.map(clip =>
      generateStoryboardFrame({
        shotDescription: clip.shot_description,
        styleAnchor: clip.consistency_anchor || params.styleAnchor,
        aspectRatio: params.aspectRatio,
        jobId: params.jobId,
        clipIndex: clip.index,
      })
    )
  )
}
